---
title: "Prediction of molecular subtypes of Breast Cancer"
output: 
  flexdashboard::flex_dashboard:
    theme: spacelab
    orientation: columns
    vertical_layout: fill
runtime: shiny
---


```{r setup, include=FALSE}
library(flexdashboard)
library(shiny)
library(DT)
library(dplyr)
library(plotly)
library(stabs)
library(factoextra)
library(NbClust)
library(FunCluster)
library(ggfortify)
library(glmnet)
require(foreign)
require(ggplot2)
require(MASS)
require(Hmisc)
require(reshape2)
library(randomForest)
library(data.table)
library(mlr)
library(h2o)
library(caret)
library(pROC)
library(jtools)
library(dplyr)
library(cluster)
library("flexclust")
library(corrplot)
library(tsne)
library(clusterCrit)
library(dplyr)
library(Matrix)
library(ggplot2)
library(cowplot)
library(randomForest)
library(Rtsne)
library(neuralnet)
library(ggplot2)
library(cowplot)
library(dplyr)
library(tidyverse)
```

```{r data}
###loading the data
clinical <- read.csv("data/clinical_data_breast_cancer.csv") 
genes <- read.csv("data/PAM50_proteins.csv")
proteomes <- read.csv("data/77_cancer_proteomes_CPTAC_itraq.csv")

###proteomes data modification
n <- proteomes$RefSeq_accession_number
proteomes <- as.data.frame(t(proteomes[,4:86]))
colnames(proteomes) <- n #add refseq
proteomes <- cbind(rownames(proteomes), data.frame(proteomes, row.names=NULL)) #separate the sample ID
colnames(proteomes)[1] <- "Complete.TCGA.ID" #the same name of column in clinical data

###sample ID
get_sample_id <- function(proteome_id) {
  x = substr(proteome_id, 4, 7)
  y = substr(proteome_id, 0, 2)
  paste("TCGA",y,x,sep="-")
}
proteomes$Complete.TCGA.ID <- sapply(proteomes$Complete.TCGA.ID, get_sample_id)
proteomes_id <- proteomes

###missing data
NA_counts <- colSums(is.na(proteomes))/nrow(proteomes)

#remove variables with >25% missing data
proteomes <- proteomes[ , colSums(is.na(proteomes))  / nrow(proteomes) < 0.25]
for (i in which(sapply(proteomes, is.numeric))) { #loop to impute means for remaining missing data
  proteomes[is.na(proteomes[, i]), i] <- mean(proteomes[, i],  na.rm = TRUE)
}
data <-  inner_join(clinical, proteomes, by = "Complete.TCGA.ID") #inner join to create full data
colnames(data)[3] <- "diag_age" #col name change for 3 column
```

Database visualization
=================================

## Column {.sidebar data-width="200"}

#### About the project

Machine learning models to classify and predict the molecular subtype of breast cancer.


## Column {data-width=500}

### Data and project description

#### Data information:
This data set contains published iTRAQ proteome profiling of 77 breast cancer samples generated by the Clinical Proteomic Tumor Analysis Consortium (NCI/NIH). It contains expression values for ~12.000 proteins for each sample, with missing values present when a given protein could not be quantified in a given sample.

##### The data set consists of: <br>
1. The decription of quantitative mass-spectrometry-based proteomic and phosphoproteomic analyses of 105 genomically annotated breast cancers, of which 77 provided high-quality data. <br>
*More information here: https://www.nature.com/articles/nature18003* <br>
2. The data about the cancer classification of a given sample using different methods. For me it was important "mRNA.PAM50" method, which I used as a training and testing data set in the Machine Learning models. <br> 
3. The list of genes and proteins used by the PAM50 classification system.
*Source of dataset: https://www.kaggle.com/piotrgrabo/breastcancerproteomes*

#### About project <br>
Using lasso regression, 50 proteins were selected to train and test machine learning models to classify and predict the molecular subtype of breast cancer. Three models were built, namely the support vector machine, random forest and artificial neural networks. In addition, the prediction using PAM50 proteins was checked on the same classification models. 

### Barplot for subtypes 

```{r reast Cancer Subtype}

renderPlotly({
###barplot
ggplot(data, aes(x=PAM50.mRNA, fill=PAM50.mRNA)) + geom_bar() + ggtitle("Breast Cancer Subtype")
})
```



## Column {.tabset}

### PCA Analysis for all BC subtypes 

#### PCA plot
```{r PCA plot}
###PCA
data.pca <- prcomp(data[,32:length(data)], center = TRUE, scale. = TRUE)
renderPlotly({
autoplot(data.pca, data = data, colour = 'PAM50.mRNA') + ggtitle("PCA Analysis for all BC subtypes")
})

```

#### PCA summary
```{r PCA sum}
reactive({summary(data.pca)})

```


### T-SNE Analysis for all BC subtypes

#### T-SNE plot

```{r T-SNE plot}
###T-SNE
data.tsne <- data
data.tsne_unique <- unique(data.tsne)
data.tsne <- as.matrix(data.tsne_unique[,32:length(data.tsne)])
set.seed(1)
data.tsne_out <- Rtsne(data.tsne, pca=FALSE, perplexity=1,dims=2, theta=0.5) # Run TSNE
tsne_plot <- data.frame(x = data.tsne_out$Y[,1], y = data.tsne_out$Y[,2], col = data.tsne_unique$PAM50.mRNA) #TSNE plot
#ggplot(tsne_plot) + geom_point(aes(x=x, y=y, color=col)) + ggtitle("T-SNE Analysis for all BC subtypes")

renderPlotly({
###barplot
ggplot(tsne_plot) + geom_point(aes(x=x, y=y, color=col)) + ggtitle("T-SNE Analysis for all BC subtypes")
})


```

#### T-SNE summary

```{r T-SNE sum}
reactive({summary(data.tsne_out$Y)})
```


Feature selection
=================================

## Column {.sidebar data-width="200"}

#### Feature selection

From the set of proteins, which contains about 12,000 proteins, a feature selection was performed by means of lasso regression. Only 50 proteins selected by the lasso entered the ML model. <br>


#### Train and test data creation

Before creating the models, the proteomic data had to be divided into a training set for the model and a test set. <br>



## Column {.tabset data-width="400"}

### Feature selection by lasso regression

<!-- ```{r lasso} -->

<!-- ## Feature selection ## -->

<!-- #creating a function to repeat lasso regression and return the selected model variables -->
<!-- LassoSub=function(k=1, Xdata, Ydata){ -->
<!--   set.seed(k) -->
<!--   s=sample(nrow(data), size=0.8*nrow(data)) -->
<!--   Xsub=Xdata[s, ] -->
<!--   Ysub=Ydata[s] -->
<!--   model.sub=cv.glmnet(x=Xsub, y=Ysub, alpha=1, family="multinomial") #cross validated lasso -->
<!--   coef.sub=coef(model.sub, s='lambda.1se')[-1] #using lambda +1se hyperparameter value for parsimony -->
<!--   return(coef.sub) -->
<!-- } -->

<!-- #Run model 100 times and save results -->
<!-- niter=100 -->
<!-- lasso.stab=sapply(1:niter, FUN=LassoSub, Xdata=as.matrix(data[,31:ncol(data)]), Ydata=as.matrix(data[,21])) -->

<!-- ###create a matrix of all predictor variables -->
<!-- lasso_matrix <- matrix(nrow=length(lasso.stab[[1]]),ncol=length(lasso.stab)) -->
<!-- rownames(lasso_matrix) <- rownames(lasso.stab[[1]]) -->
<!-- for (i in 1:300){ #loop through to put list contents into matrix -->
<!--   lasso.data.frame <- as.matrix(lasso.stab[[i]]) -->
<!--   lasso_matrix[,i] <- lasso.data.frame -->
<!-- } -->
<!-- lasso_matrix <- ifelse(lasso_matrix != 0, 1, 0) #binary values 1/0 (selected/not selected) -->
<!-- lasso_matrix <- lasso_matrix[2:nrow(lasso_matrix),] -->
<!-- stable_variables <- as.data.frame(rowSums(lasso_matrix)) #data frame with count of how many times each variable is selected for a model -->
<!-- stable_variables$protein <- rownames(stable_variables) #column of variable names -->
<!-- colnames(stable_variables)[1] <- "times" -->
<!-- stable_variables <- stable_variables[!is.na(stable_variables$times),]  #remove NAs -->
<!-- stable_variables <- stable_variables[stable_variables$times != 0,] #remove all not selected variables -->
<!-- stable_variables <- stable_variables[order(-stable_variables$times),] #ordering by times  -->
<!-- write.table(stable_variables[1:50,], "stable_variables.csv", col.names = T, row.names = T, sep = ",") -->

<!-- ``` -->

```{r lasso plot for 50 first proteins}
stable_variables <- read.csv("data/stable_variables.csv")

###plotting 50 stable variables
renderPlotly({
(ggplot(stable_variables[1:50,], aes(x=reorder(as.factor(protein),-abs(times),mean), 
                                    y=times, col =reorder(as.factor(protein),-abs(times),mean), 
                                    fill =reorder(as.factor(protein),-abs(times),mean))) 
  + geom_col(show.legend = FALSE, alpha = 0.6) + theme(axis.text.x = element_text(angle = 90, hjust = 1), 
                                                       axis.text=element_text(size=10)) 
  + xlab("Protein ID") + ylab("Times selected")
  + ggtitle("Stable variables obtained by Lasso regression"))
})
```

```{r 50 stable_variables}
stab_var <- stable_variables$protein[1:50] 
stab_var.ind <- which(colnames(data) %in% stab_var)
```




### Annotated proteins using biomaRt

Annotated proteins using biomaRt which were selected by lasso regression.

```{r 50 stable_variables table}
lasso_protein <- read.csv("Lasso_proteins.csv")

DT::renderDataTable({

 DT::datatable(lasso_protein, 
 rownames = FALSE, colnames = c('Refseq peptide', 'External gene name', 'Entrezgene description', "Times from lasso regression"), 
 extensions = c('Buttons', 'Responsive'), 
 options = list(columnDefs = list(list(className = 'dt-center', targets = "_all")), dom = 'Blfrt', 
 buttons = c('copy', 'csv', 'excel'), searching = FALSE, scrollY = 300, scrollCollapse = TRUE))
 
})


```



## Column {data-width="300"}

### Train and test dataset

The data set was divided into a training set and a test set in the ratio of 7/10 to 3/10 for machine learning models.


```{r test and train dataset}
## Creation the train and test data ###

###test and train split index
set.seed(1)
samp <- createDataPartition(data$PAM50.mRNA, p = 0.7, list = FALSE)
train_data <- data[samp, c(21, stab_var.ind)]
#summary(train_data)
test_data <- data[-samp, c(21, stab_var.ind)]
#summary(test_data)

###test and train data barplot
train_data.plot <- train_data
train_data.plot$data <- "train_data"
test_data.plot <- test_data
test_data.plot$data <- "test_data"
train_data.plot <- t(train_data.plot)
test_data.plot <- t(test_data.plot)
data.plot <- cbind.data.frame(train_data.plot,test_data.plot)
data.plot <- t(data.plot)
data.plot <- as.data.frame(data.plot)

renderPlotly({
  ggplot(data.plot, aes(x=PAM50.mRNA, fill=data)) + geom_bar() +  ggtitle("train_data (0.7) & test_data (0.3) for Lasso proteins")
  })

```


Models
=================================

## Column {.sidebar data-width="200"}

#### Models building for Lasso data
The three models were created for the Lasso data: <br>
* Support-Vector Machine <br>
* Random Forest <br>
* Neural Network Classifier <br>


## Column {.tabset data-width="450"}

### Confusion Matrix

#### Random Forest


```{r random forest model}
set.seed(1)
random.forest.mod <- randomForest(as.factor(PAM50.mRNA) ~ ., 
                                  data=train_data, 
                                  ntree = 500, 
                                  mtry = 8, 
                                  importance = TRUE) #training
#plot(random.forest.mod)
```


```{r random forest matrix}
random.forest.predicts <- predict(random.forest.mod, newdata=test_data, type = "class") #prediction

rf.cm <- confusionMatrix(random.forest.predicts, as.factor(test_data$PAM50.mRNA), dnn = c("Prediction", "Reference")) #confusion matrix
  

rf.plt <- as.data.frame(rf.cm$table)
rf.plt$Prediction <- factor(rf.plt$Prediction, levels=rev(levels(rf.plt$Prediction)))

renderPlotly({
  
  ggplot(rf.plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#1245b3") +
        labs(x = "Reference",y = "Prediction") +
        scale_x_discrete(labels=c("Luminal B","Luminal A","HER2-enriched","Basal-like")) +
        scale_y_discrete(labels=c("Basal-like","HER2-enriched","Luminal A","Luminal B"))
  
})



```



#### SVM

```{r svm model}
###Support-Vector Machine
set.seed(1)
#settng up train control for cross validation and calibration of hyperparameter
train_control <- trainControl(method="repeatedcv", 
                              number=3, 
                              repeats=10, 
                              savePredictions = TRUE, 
                              summaryFunction = multiClassSummary) 
grid <- expand.grid(C = seq(0.000001,0.15,0.002)) #Tunegrid for different values of C
set.seed(1)
svm.lin.mod <- train(PAM50.mRNA ~ ., 
                     data=train_data, 
                     trControl=train_control, 
                     method="svmLinear", 
                     preProcess = c("center","scale"), 
                     tuneGrid =grid, 
                     tuneLength = 10) #training
svm.predicts <- predict(svm.lin.mod, 
                        newdata = test_data) #Creating predictions on test set

```


```{r svm confusion matrix}

svm.cm<- confusionMatrix(svm.predicts, as.factor(test_data$PAM50.mRNA),dnn = c("Prediction", "Reference")) #confusion matrix

svm.plt <- as.data.frame(svm.cm$table)
svm.plt$Prediction <- factor(svm.plt$Prediction, levels=rev(levels(svm.plt$Prediction)))

renderPlotly({
  
  ggplot(svm.plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#1245b3") +
        labs(x = "Reference",y = "Prediction") +
        scale_x_discrete(labels=c("Luminal B","Luminal A","HER2-enriched","Basal-like")) +
        scale_y_discrete(labels=c("Basal-like","HER2-enriched","Luminal A","Luminal B"))
  
})



```


#### Neural Network Calssifier

```{r nn model, include=FALSE}
###Neural Network Classifier
neural.network.mod <-neuralnet(as.factor(PAM50.mRNA) ~ .,          
                               data=train_data, 
                               hidden = c(30, 15, 8), 
                               linear.output = FALSE,
                               act.fct = "logistic",
                               algorithm = 'sag')

neural.network.mod$result.matrix #errors for model
neural.network.predicts <- compute(neural.network.mod, test_data) #prediction
neural.network.res = neural.network.predicts$net.result #results of prediction
neural.network.res=data.frame("neural.network.res"=ifelse(max.col(neural.network.res[ ,1:4])==1, "Basal-like",
                              ifelse(max.col(neural.network.res[ ,1:4])==2, "HER2-enriched",
                              ifelse(max.col(neural.network.res[ ,1:4])==3, "Luminal A", "Luminal B"))))

```


<!-- ```{r nn plot} -->
<!-- plot(neural.network.mod, -->
<!--      intercept = F, -->
<!--      rep = 'best', -->
<!--      col.hidden = 'darkblue',  -->
<!--      col.hidden.synapse = 'black',  -->
<!--      show.weights = F,  -->
<!--      fill = 'lightblue', -->
<!--      col.intercept	= 'red', -->
<!--      fontsize = 8,  -->
<!--      dimension = 15) -->

<!-- ``` -->


```{r nn confusion matrix}


nnc.cm <- confusionMatrix(as.factor(test_data$PAM50.mRNA), as.factor(neural.network.res$neural.network.res), dnn = c("Prediction", "Reference"))


nnc.plt <- as.data.frame(nnc.cm$table)
nnc.plt$Prediction <- factor(nnc.plt$Prediction, levels=rev(levels(nnc.plt$Prediction)))

renderPlotly({
  
  ggplot(nnc.plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="#1245b3") +
        labs(x = "Reference",y = "Prediction") +
        scale_x_discrete(labels=c("Luminal B","Luminal A","HER2-enriched","Basal-like")) +
        scale_y_discrete(labels=c("Basal-like","HER2-enriched","Luminal A","Luminal B"))
  
})


```


### Statistics by Class 

#### Random Forest

```{r model compresion rf}

#data frame of res
df.rf <- data.frame(rf.cm$byClass)
df.rf  <- df.rf[,c(1,2,5,6,7)]

df.rf <- data.frame(models=rownames(df.rf),
                 Sensitivity=df.rf[,1], Specificity=df.rf[,2], Precision=df.rf[,3],
                 Recall=df.rf[,4], F1=df.rf[,5])
                 

#Melt
df1.rf <- df.rf %>% pivot_longer(cols = -models)

#Plot
renderPlotly({
  
  ggplot(df1.rf,aes(x=name,y=value,fill=models,label=paste0(100*round(value,3),'%')))+
  geom_bar(stat='identity',position = 'dodge')+
  geom_text(position = position_dodge(0.9),vjust=-0.25)+
  theme(legend.position = 'bottom')
  
})

```

#### SVM

```{r model compresion svm}

df.svm <- data.frame(svm.cm$byClass)
df.svm <- df.svm[,c(1,2,5,6,7)]

df.svm <- data.frame(models=rownames(df.svm),
                 Sensitivity=df.svm[,1], Specificity=df.svm[,2], Precision=df.svm[,3],
                 Recall=df.svm[,4], F1=df.svm[,5])
                 

#Melt
df1.svm <- df.svm %>% pivot_longer(cols = -models)

#Plot
renderPlotly({
  
  ggplot(df1.svm,aes(x=name,y=value,fill=models,label=paste0(100*round(value,3),'%')))+
  geom_bar(stat='identity',position = 'dodge')+
  geom_text(position = position_dodge(0.9),vjust=-0.25)+
  theme(legend.position = 'bottom')
  
})

```


#### Neural Network Classifier

```{r model compresion nnc}

df.nnc <- data.frame(nnc.cm$byClass)
df.nnc <- df.nnc[,c(1,2,5,6,7)]

df.nnc <- data.frame(models=rownames(df.nnc),
                 Sensitivity=df.nnc[,1], Specificity=df.nnc[,2], Precision=df.nnc[,3],
                 Recall=df.nnc[,4], F1=df.nnc[,5])
                 

#Melt
df1.nnc <- df.nnc %>% pivot_longer(cols = -models)

#Plot
renderPlotly({
  
  ggplot(df1.nnc,aes(x=name,y=value,fill=models,label=paste0(100*round(value,3),'%')))+
  geom_bar(stat='identity',position = 'dodge')+
  geom_text(position = position_dodge(0.9),vjust=-0.25)+
  theme(legend.position = 'bottom')
  
})

```




## Column {data-width="300"}

### Model Compresion - Overall Statistics

```{r model compresion}

#data frame of res
df <- data.frame(models=c('Random Forest','SVM', 'Neural Network Classifier'),
                 Accuracy=c(rf.cm$overall[[1]],svm.cm$overall[[1]],nnc.cm$overall[[1]]),
                 Kappa=c(rf.cm$overall[[2]],svm.cm$overall[[2]],nnc.cm$overall[[2]]))
#Melt
df1 <- df %>% pivot_longer(cols = -models)

#Plot
renderPlotly({
  
  ggplot(df1,aes(x=name,y=value,fill=models,label=paste0(100*round(value,3),'%')))+
  geom_bar(stat='identity',position = 'dodge')+
  geom_text(position = position_dodge(0.9),vjust=-0.25)+
  theme(legend.position = 'bottom')
  
})

```



```{css}

.dt-center {
  background-color: #678EB9;
  color: #FFFFFF;
  font-family: "Lucida Console", "Courier New", monospace; 
  font-size: 12px;
}

#section-section .shiny-bound-output {
  background-color: #678EB9;
  color: #FFFFFF;
  font-family: "Lucida Console", "Courier New", monospace; 
  font-size: 12px;
}


```
